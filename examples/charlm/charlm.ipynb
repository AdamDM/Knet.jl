{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character based RNN language model trained on 'The Complete Works of William Shakespeare'\n",
    "Based on http://karpathy.github.io/2015/05/21/rnn-effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNTYPE = :lstm\n",
    "BATCHSIZE = 256\n",
    "SEQLENGTH = 100\n",
    "INPUTSIZE = 168\n",
    "VOCABSIZE = 84\n",
    "HIDDENSIZE = 334\n",
    "NUMLAYERS = 1\n",
    "DROPOUT = 0.0\n",
    "LR=0.001\n",
    "BETA_1=0.9\n",
    "BETA_2=0.999\n",
    "EPS=1e-08\n",
    "EPOCHS = 30;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"4925284-element Array{UInt8,1}\", \"525665-element Array{UInt8,1}\", \"84-element Array{Char,1}\")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load 'The Complete Works of William Shakespeare'\n",
    "using Knet\n",
    "include(Knet.dir(\"data\",\"gutenberg.jl\"))\n",
    "trn,tst,chars = shakespeare()\n",
    "map(summary,(trn,tst,chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Cheated of feature by dissembling nature,\r\n",
      "    Deform'd, unfinish'd, sent before my time\r\n",
      "    Into this breathing world scarce half made up,\r\n",
      "    And that so lamely and unfashionable\r\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "# Print a sample\n",
    "println(string(chars[trn[1020:1210]]...)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 20)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minibatch data\n",
    "function mb(a)\n",
    "    N = div(length(a),BATCHSIZE)\n",
    "    x = reshape(a[1:N*BATCHSIZE],N,BATCHSIZE)' # reshape full data to (B,N) with contiguous rows\n",
    "    minibatch(x[:,1:N-1], x[:,2:N], SEQLENGTH) # split into (B,T) blocks \n",
    "end\n",
    "dtrn,dtst = mb(trn),mb(tst)\n",
    "map(length, (dtrn,dtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "function initmodel()\n",
    "    w(d...)=KnetArray(xavier(Float32,d...))\n",
    "    b(d...)=KnetArray(zeros(Float32,d...))\n",
    "    r,wr = rnninit(INPUTSIZE,HIDDENSIZE,rnnType=RNNTYPE,numLayers=NUMLAYERS,dropout=DROPOUT)\n",
    "    wx = w(INPUTSIZE,VOCABSIZE)\n",
    "    wy = w(VOCABSIZE,HIDDENSIZE)\n",
    "    by = b(VOCABSIZE,1)\n",
    "    r,(wr,wx,wy,by)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and its gradient\n",
    "function predict(r,ws,xs,hx,cx)\n",
    "    wr,wx,wy,by = ws\n",
    "    x = wx[:,xs]                                    # xs=(B,T) x=(X,B,T)\n",
    "    x = dropout(x,DROPOUT)\n",
    "    y,hy,cy = rnnforw(r,wr,x,hx,cx,hy=true,cy=true) # y=(H,B,T) hy=cy=(H,B,L)\n",
    "    y = dropout(y,DROPOUT)\n",
    "    y2 = reshape(y,size(y,1),size(y,2)*size(y,3))   # y2=(H,B*T)\n",
    "    return wy*y2.+by, hy, cy\n",
    "end\n",
    "\n",
    "function loss(r,w,x,y,h)\n",
    "    py,hy,cy = predict(r,w,x,h...)\n",
    "    h[1],h[2] = getval(hy),getval(cy)\n",
    "    return nll(py,y)\n",
    "end\n",
    "\n",
    "lossgradient = gradloss(loss,2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test loops\n",
    "function train(rnn,weights,data,optim)\n",
    "    hiddens = Any[nothing,nothing]\n",
    "    losses = []\n",
    "    for (x,y) in data\n",
    "        grads,loss1 = lossgradient(rnn,weights,x,y,hiddens)\n",
    "        update!(weights, grads, optim)\n",
    "        push!(losses, loss1)\n",
    "    end\n",
    "    return mean(losses)\n",
    "end\n",
    "\n",
    "function test(rnn,weights,data)\n",
    "    hiddens = Any[nothing,nothing]\n",
    "    losses = []\n",
    "    for (x,y) in data\n",
    "        push!(losses, loss(rnn,weights,x,y,hiddens))\n",
    "    end\n",
    "    return mean(losses)\n",
    "end; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "rnn=weights=optim=nothing; knetgc()\n",
    "rnn,weights = initmodel()\n",
    "optim = optimizers(weights, Adam; lr=LR, beta1=BETA_1, beta2=BETA_2, eps=EPS);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mTraining...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17.084233 seconds (253.34 k allocations: 132.278 MiB, 0.04% gc time)\n",
      "  0.607702 seconds (38.99 k allocations: 10.744 MiB)\n",
      "(:epoch, 1, :trnppl, 17.664436f0, :tstppl, 9.183411f0)\n",
      " 16.843650 seconds (232.61 k allocations: 131.185 MiB, 0.04% gc time)\n",
      "  0.546336 seconds (8.24 k allocations: 9.039 MiB, 0.18% gc time)\n",
      "(:epoch, 2, :trnppl, 7.6239805f0, :tstppl, 6.705649f0)\n",
      " 16.907754 seconds (233.63 k allocations: 131.201 MiB, 0.03% gc time)\n",
      "  0.552095 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 3, :trnppl, 6.1014156f0, :tstppl, 5.7781134f0)\n",
      " 17.008465 seconds (234.47 k allocations: 131.212 MiB, 0.03% gc time)\n",
      "  0.551228 seconds (7.79 k allocations: 9.032 MiB, 0.16% gc time)\n",
      "(:epoch, 4, :trnppl, 5.393814f0, :tstppl, 5.245802f0)\n",
      " 17.086273 seconds (235.00 k allocations: 131.220 MiB, 0.03% gc time)\n",
      "  0.553913 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 5, :trnppl, 4.933017f0, :tstppl, 4.8756704f0)\n",
      " 17.130323 seconds (234.47 k allocations: 131.212 MiB, 0.03% gc time)\n",
      "  0.555645 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 6, :trnppl, 4.6037984f0, :tstppl, 4.6119456f0)\n",
      " 17.156276 seconds (234.47 k allocations: 131.212 MiB, 0.03% gc time)\n",
      "  0.552752 seconds (8.24 k allocations: 9.039 MiB, 0.17% gc time)\n",
      "(:epoch, 7, :trnppl, 4.3505673f0, :tstppl, 4.402083f0)\n",
      " 17.150259 seconds (234.54 k allocations: 131.214 MiB, 0.04% gc time)\n",
      "  0.556728 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 8, :trnppl, 4.155052f0, :tstppl, 4.242699f0)\n",
      " 17.201074 seconds (234.47 k allocations: 131.212 MiB, 0.04% gc time)\n",
      "  0.561400 seconds (7.85 k allocations: 9.033 MiB, 0.16% gc time)\n",
      "(:epoch, 9, :trnppl, 3.9959533f0, :tstppl, 4.1168947f0)\n",
      " 17.173483 seconds (235.00 k allocations: 131.220 MiB, 0.03% gc time)\n",
      "  0.560071 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 10, :trnppl, 3.870566f0, :tstppl, 4.0540934f0)\n",
      " 17.205842 seconds (234.47 k allocations: 131.212 MiB, 0.03% gc time)\n",
      "  0.553411 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 11, :trnppl, 3.7684019f0, :tstppl, 3.9255006f0)\n",
      " 17.211617 seconds (234.46 k allocations: 131.212 MiB, 0.03% gc time)\n",
      "  0.558317 seconds (8.23 k allocations: 9.039 MiB, 0.16% gc time)\n",
      "(:epoch, 12, :trnppl, 3.6828055f0, :tstppl, 3.8493032f0)\n",
      " 17.179212 seconds (234.53 k allocations: 131.213 MiB, 0.03% gc time)\n",
      "  0.555932 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 13, :trnppl, 3.611577f0, :tstppl, 3.7841012f0)\n",
      " 17.193160 seconds (234.47 k allocations: 131.212 MiB, 0.03% gc time)\n",
      "  0.557632 seconds (7.84 k allocations: 9.033 MiB, 0.17% gc time)\n",
      "(:epoch, 14, :trnppl, 3.5509245f0, :tstppl, 3.7330313f0)\n",
      " 17.195681 seconds (234.92 k allocations: 131.219 MiB, 0.03% gc time)\n",
      "  0.555164 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 15, :trnppl, 3.4964538f0, :tstppl, 3.689003f0)\n",
      " 17.175100 seconds (234.47 k allocations: 131.212 MiB, 0.03% gc time)\n",
      "  0.554608 seconds (7.45 k allocations: 9.027 MiB, 0.15% gc time)\n",
      "(:epoch, 16, :trnppl, 3.4498737f0, :tstppl, 3.652695f0)\n",
      " 17.171803 seconds (231.41 k allocations: 131.166 MiB, 0.03% gc time)\n",
      "  0.559251 seconds (8.31 k allocations: 9.040 MiB, 0.18% gc time)\n",
      "(:epoch, 17, :trnppl, 3.4085603f0, :tstppl, 3.6118238f0)\n",
      " 17.198821 seconds (234.46 k allocations: 131.212 MiB, 0.04% gc time)\n",
      "  0.559947 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 18, :trnppl, 3.3735187f0, :tstppl, 3.5840726f0)\n",
      " 17.216949 seconds (234.46 k allocations: 131.212 MiB, 0.03% gc time)\n",
      "  0.556553 seconds (7.92 k allocations: 9.034 MiB, 0.28% gc time)\n",
      "(:epoch, 19, :trnppl, 3.3395152f0, :tstppl, 3.5536046f0)\n",
      " 17.168345 seconds (234.87 k allocations: 131.218 MiB, 0.03% gc time)\n",
      "  0.556786 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 20, :trnppl, 3.308609f0, :tstppl, 3.5261805f0)\n",
      " 17.213235 seconds (234.47 k allocations: 131.212 MiB, 0.03% gc time)\n",
      "  0.556750 seconds (7.53 k allocations: 9.028 MiB, 0.16% gc time)\n",
      "(:epoch, 21, :trnppl, 3.2875803f0, :tstppl, 3.5433521f0)\n",
      " 17.180844 seconds (235.33 k allocations: 131.226 MiB, 0.03% gc time)\n",
      "  0.558013 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 22, :trnppl, 3.2632916f0, :tstppl, 3.483339f0)\n",
      " 17.186034 seconds (234.39 k allocations: 131.211 MiB, 0.04% gc time)\n",
      "  0.556446 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 23, :trnppl, 3.235033f0, :tstppl, 3.4642138f0)\n",
      " 17.198893 seconds (234.47 k allocations: 131.212 MiB, 0.03% gc time)\n",
      "  0.554194 seconds (7.97 k allocations: 9.035 MiB, 0.18% gc time)\n",
      "(:epoch, 24, :trnppl, 3.2131104f0, :tstppl, 3.4468985f0)\n",
      " 17.183478 seconds (234.79 k allocations: 131.217 MiB, 0.04% gc time)\n",
      "  0.555249 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 25, :trnppl, 3.193985f0, :tstppl, 3.4347878f0)\n",
      " 17.206950 seconds (234.47 k allocations: 131.212 MiB, 0.04% gc time)\n",
      "  0.555463 seconds (7.58 k allocations: 9.029 MiB, 0.18% gc time)\n",
      "(:epoch, 26, :trnppl, 3.1765814f0, :tstppl, 3.4175692f0)\n",
      " 17.208548 seconds (235.26 k allocations: 131.224 MiB, 0.03% gc time)\n",
      "  0.555791 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 27, :trnppl, 3.1590703f0, :tstppl, 3.406445f0)\n",
      " 17.198054 seconds (234.39 k allocations: 131.211 MiB, 0.04% gc time)\n",
      "  0.557304 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 28, :trnppl, 3.1427407f0, :tstppl, 3.3949728f0)\n",
      " 17.175172 seconds (234.47 k allocations: 131.212 MiB, 0.04% gc time)\n",
      "  0.556475 seconds (8.05 k allocations: 9.036 MiB, 0.17% gc time)\n",
      "(:epoch, 29, :trnppl, 3.1276414f0, :tstppl, 3.3863392f0)\n",
      " 17.208891 seconds (234.79 k allocations: 131.217 MiB, 0.04% gc time)\n",
      "  0.554629 seconds (4.40 k allocations: 8.980 MiB)\n",
      "(:epoch, 30, :trnppl, 3.11333f0, :tstppl, 3.3788717f0)\n",
      "531.366722 seconds (7.35 M allocations: 4.114 GiB, 0.04% gc time)\n"
     ]
    }
   ],
   "source": [
    "info(\"Training...\")\n",
    "@time for epoch in 1:EPOCHS\n",
    "    @time trnloss = train(rnn,weights,dtrn,optim) # ~18 seconds\n",
    "    @time tstloss = test(rnn,weights,dtst)        # ~0.5 seconds\n",
    "    println((:epoch, epoch, :trnppl, exp(trnloss), :tstppl, exp(tstloss)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Obeath for him e'en take he.\n",
      "  CASSIO. Glad my long-string necessery, come, do Ebsero.\n",
      "    And when he hie's battles, his father's queen!\n",
      "    And though thou not so brufy to hear and\n",
      "    Locke the castle the mouldy murtherers of your\n",
      "    To charge thee a child shin, I was all. When draws Tit\n",
      "    After sheek for merect to good where,\n",
      "    Strike, try, Christman, of the death of comfort,\n",
      "    And struttians, commvan-kinver in't.\n",
      "  LYSANDER. So, my lord.\n",
      "  TIMON. They could not conduct hawh'b done, by my gusts,\n",
      "    And shall wear me what common an ene?\n",
      "    To this, and weak a secuad, which never find\n",
      "    To bed, indeed, truly asham'd out of gracious hars!\n",
      "    They pleds her own fault.\n",
      "  SHYLOCK. Caesar I now hurt, I do; what, right and air stands?\n",
      "  FIRST BACWBRGMAM. And ask them, away these rush blood; and this I can not\n",
      "    unfector the noble traitor to command'nor I bear her.\n",
      "  CORIOLANUS. From your fools of two order of starp, but letter\n",
      "    With like guards to re\n"
     ]
    }
   ],
   "source": [
    "# Sample from trained model\n",
    "function generate(rnn,weights,n)\n",
    "    function sample(y)\n",
    "        p,r=Array(exp.(y-logsumexp(y))),rand()\n",
    "        for j=1:length(p); (r -= p[j]) < 0 && return j; end\n",
    "    end\n",
    "    h,c = nothing,nothing\n",
    "    x = findfirst(chars,'\\n')\n",
    "    for i=1:n\n",
    "        y,h,c = predict(rnn,weights,[x],h,c)\n",
    "        x = sample(y)\n",
    "        print(chars[x])\n",
    "    end\n",
    "    println()\n",
    "end\n",
    "\n",
    "generate(rnn,weights,1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
