{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet, Plots, Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear regression example with housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"13×506 Array{Float64,2}\", \"1×506 Array{Float64,2}\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the housing dataset from the UCI Machine Learning Repository\n",
    "include(Pkg.dir(\"Knet\",\"data\",\"housing.jl\"))\n",
    "x,y = housing()\n",
    "map(summary,(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss\n",
    "predict(w,x) = w[1]*x .+ w[2]\n",
    "loss(w,x,y) = mean(abs2,y-predict(w,x))\n",
    "lossgradient = grad(loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Any,1}:\n",
       "  [0.0533183 0.0454029 … 0.0160006 0.0422956]\n",
       " 0.0                                         "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "srand(42)\n",
    "w = [ 0.1*rand(1,13), 0.0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594.435239388768"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(w,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Any,1}:\n",
       "    [7.53003 -6.79923 … -6.369 13.8655]\n",
       " -45.0656                              "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossgradient(w,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the gradient: Increasing w[2] by eps should decrease loss by 45.0656 * eps\n",
    "w[2]=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589.9386781239458"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(w,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD training loop\n",
    "function train!(w, data; lr=.1)\n",
    "    for (x,y) in data\n",
    "        dw = lossgradient(w, x, y)\n",
    "        for i in 1:length(w)\n",
    "            w[i] -= lr * dw[i]\n",
    "        end\n",
    "    end\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.146968 seconds (443.46 k allocations: 17.372 MiB, 5.56% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10-element Array{Array{Any,1},1}:\n",
       " Any[[-0.699684 0.725326 … 0.652901 -1.34426], 4.58656]\n",
       " Any[[-0.551026 0.513913 … 0.565058 -1.53221], 8.17581]\n",
       " Any[[-0.59464 0.518516 … 0.634074 -1.88846], 11.0472] \n",
       " Any[[-0.590579 0.487521 … 0.663802 -2.1303], 13.3443] \n",
       " Any[[-0.594767 0.473771 … 0.698189 -2.33759], 15.182] \n",
       " Any[[-0.596189 0.463224 … 0.727585 -2.50545], 16.6522]\n",
       " Any[[-0.598128 0.457414 … 0.754282 -2.64491], 17.8283]\n",
       " Any[[-0.600288 0.454846 … 0.777929 -2.7612], 18.7692] \n",
       " Any[[-0.602933 0.455003 … 0.798796 -2.8591], 19.5219] \n",
       " Any[[-0.606062 0.457353 … 0.817038 -2.94219], 20.1241]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Record the weights for 10 epochs\n",
    "@time weights = [ copy(train!(w, [(x, y)])) for epoch=1:10 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float64,1}:\n",
       " 364.412 \n",
       " 240.165 \n",
       " 161.982 \n",
       " 112.161 \n",
       "  80.3404\n",
       "  59.9844\n",
       "  46.9397\n",
       "  38.5626\n",
       "  33.1684\n",
       "  29.6825"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = [ loss(w,x,y) for w in weights ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(losses,xlabel=\"Epochs\",ylabel=\"Loss\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and minibatch MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mLoading MNIST...\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "include(Knet.dir(\"data\",\"mnist.jl\"))\n",
    "xtrn,ytrn,xtst,ytst = mnist()\n",
    "Atype = gpu() >= 0 ? KnetArray{Float32} : Array{Float32}\n",
    "dtst = minibatch(xtst,ytst,100;xtype=Atype); # [ (x1,y1), (x2,y2), ... ] where xi,yi are minibatches of 100\n",
    "dtrn = minibatch(xtrn,ytrn,100;xtype=Atype); # [ (x1,y1), (x2,y2), ... ] where xi,yi are minibatches of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtrn and dtst are iterables of (x,y) minibatches, each minibatch contains 100 instances\n",
    "length(dtrn),length(dtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the first three test images and labels\n",
    "(x,y) = first(dtst)\n",
    "ax = Array(x)\n",
    "for i=1:3; display(mnistview(ax,i)); end\n",
    "y[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax classification example with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define softmax loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss\n",
    "predict(w,x) = w[1]*mat(x) .+ w[2]  # Same as linreg except we need mat() to convert input 4D->2D before matmul\n",
    "loss(w,x,ygold) = nll(predict(w,x),ygold); # nll is negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "wsoft=map(Atype, [ 0.1*randn(10,784), zeros(10,1) ]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5499191f0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average loss for a single (x,y) minibatch\n",
    "loss(wsoft, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4640574f0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average loss for the whole test set\n",
    "nll(wsoft,dtst,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1488"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy for the whole test set\n",
    "accuracy(wsoft,dtst,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train softmax model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19.008759 seconds (15.15 M allocations: 11.134 GiB, 7.24% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time softmodels = [ copy(train!(wsoft, dtrn)) for epoch=1:60 ];  # ~17 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot softmax learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12.331779 seconds (4.96 M allocations: 10.709 GiB, 9.06% gc time)\n",
      "  2.060784 seconds (833.65 k allocations: 1.785 GiB, 9.50% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time trnsoftloss = [ nll(w,dtrn,predict) for w in softmodels ];  # ~13 seconds\n",
    "@time tstsoftloss = [ nll(w,dtst,predict) for w in softmodels ];  # ~2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([trnsoftloss tstsoftloss],ylim=(.2,.36),labels=[:trnsoftloss :tstsoftloss],xlabel=\"Epochs\",ylabel=\"Loss\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot softmax error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11.313936 seconds (3.51 M allocations: 10.989 GiB, 7.73% gc time)\n",
      "  1.973695 seconds (592.42 k allocations: 1.832 GiB, 7.79% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time trnsofterr = [ 1-accuracy(w,dtrn,predict) for w in softmodels ];  # ~12 seconds\n",
    "@time tstsofterr = [ 1-accuracy(w,dtst,predict) for w in softmodels ];  # ~2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot([trnsofterr tstsofterr],ylim=(.06,.10),labels=[:trnsofterr :tstsofterr],xlabel=\"Epochs\",ylabel=\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "wsoft = softmodels = nothing; knetgc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer perceptron example with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only need to change the predict function!\n",
    "function predict(w,x)\n",
    "    for i=1:2:length(w)\n",
    "        x = w[i]*mat(x) .+ w[i+1]\n",
    "        if i<length(w)-1\n",
    "            x = max.(0,x)                         \n",
    "        end\n",
    "    end\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3692908f0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmlp=map(Atype, [ 0.1*randn(64,784), zeros(64,1), \n",
    "                  0.1*randn(10,64),  zeros(10,1) ])\n",
    "loss(wmlp, x, y)  # average loss for random model should be close to log(10)=2.3026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21.118867 seconds (22.10 M allocations: 11.377 GiB, 6.54% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time mlpmodels = [ copy(train!(wmlp, dtrn)) for epoch=1:60 ]; # ~20 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare MLP loss with softmax loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11.290381 seconds (6.25 M allocations: 10.747 GiB, 6.85% gc time)\n",
      "  1.998621 seconds (1.05 M allocations: 1.792 GiB, 7.60% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time trnmlploss = [ nll(w,dtrn,predict) for w in mlpmodels ]; # ~12 seconds\n",
    "@time tstmlploss = [ nll(w,dtst,predict) for w in mlpmodels ]; # ~2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([trnsoftloss tstsoftloss trnmlploss tstmlploss],ylim=(.0,.36),labels=[:trnsoftloss :tstsoftloss :trnmlploss :tstmlploss],xlabel=\"Epochs\",ylabel=\"Loss\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare MLP error with softmax error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10.683939 seconds (4.80 M allocations: 11.027 GiB, 7.23% gc time)\n",
      "  1.864670 seconds (808.95 k allocations: 1.838 GiB, 7.31% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time trnmlperr = [ 1-accuracy(w,dtrn,predict) for w in mlpmodels ]; # ~13 seconds\n",
    "@time tstmlperr = [ 1-accuracy(w,dtst,predict) for w in mlpmodels ]; # ~2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot([trnsofterr tstsofterr trnmlperr tstmlperr],ylim=(.0,.10),labels=[:trnsofterr :tstsofterr :trnmlperr :tstmlperr],xlabel=\"Epochs\",ylabel=\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "wmlp = mlpmodels = nothing; knetgc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN example with MNIST (The LeNet model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only need to change the predict function!\n",
    "function predict(w,x) # LeNet model\n",
    "    n=length(w)-4\n",
    "    for i=1:2:n\n",
    "        x = pool(relu.(conv4(w[i],x) .+ w[i+1]))\n",
    "    end\n",
    "    for i=n+1:2:length(w)-2\n",
    "        x = relu.(w[i]*mat(x) .+ w[i+1])\n",
    "    end\n",
    "    return w[end-1]*x .+ w[end]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7416694f0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcnn=map(Atype, [ 0.1*randn(5,5,1,20),  zeros(1,1,20,1), \n",
    "                  0.1*randn(5,5,20,50), zeros(1,1,50,1),\n",
    "                  0.1*randn(500,800),  zeros(500,1),\n",
    "                  0.1*randn(10,500),  zeros(10,1) ])\n",
    "loss(wcnn, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133.198253 seconds (52.50 M allocations: 12.672 GiB, 2.17% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time cnnmodels = [ copy(train!(wcnn, dtrn)) for epoch=1:60 ]; # ~127 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare CNN loss with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49.636573 seconds (15.47 M allocations: 11.124 GiB, 2.15% gc time)\n",
      "  8.291805 seconds (2.59 M allocations: 1.854 GiB, 2.25% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time trncnnloss = [ nll(w,dtrn,predict) for w in cnnmodels ]; # ~48 seconds\n",
    "@time tstcnnloss = [ nll(w,dtst,predict) for w in cnnmodels ]; # ~8 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([trnsoftloss tstsoftloss trnmlploss tstmlploss trncnnloss tstcnnloss],ylim=(.0,.36),labels=[:trnsoftloss :tstsoftloss :trnmlploss :tstmlploss :trncnnloss :tstcnnloss],xlabel=\"Epochs\",ylabel=\"Loss\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare CNN error with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48.654533 seconds (14.02 M allocations: 11.404 GiB, 2.32% gc time)\n",
      "  8.125216 seconds (2.34 M allocations: 1.901 GiB, 2.45% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time trncnnerr = [ 1-accuracy(w,dtrn,predict) for w in cnnmodels ]; # ~48 seconds\n",
    "@time tstcnnerr = [ 1-accuracy(w,dtst,predict) for w in cnnmodels ]; # ~8 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot([trnsofterr tstsofterr trnmlperr tstmlperr trncnnerr tstcnnerr],ylim=(.0,.10),labels=[:trnsofterr :tstsofterr :trnmlperr :tstmlperr :trncnnerr :tstcnnerr],xlabel=\"Epochs\",ylabel=\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "wcnn = cnnmodels = nothing; knetgc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakespeare example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please see charlm.ipynb for training a character based language model on \"The Complete Works of William Shakespeare\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(Knet.dir(\"examples/vgg/vgg.jl\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caturl = \"https://github.com/BVLC/caffe/raw/master/examples/images/cat.jpg\"\n",
    "catfile = download(caturl)\n",
    "load(catfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg.jl (c) Deniz Yuret, İlker Kesen, 2016. Classifying images with the VGG model from http://www.robots.ox.ac.uk/~vgg/research/very_deep.\n",
      "opts=(:atype, \"KnetArray{Float32}\")(:top, 5)(:image, \"/dev/shm/dyuret/.julia/v0.6/Knet/data/cat.jpg\")(:model, \"imagenet-vgg-verydeep-16\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mLoading imagenet-vgg-verydeep-16.mat...\n",
      "\u001b[39m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5×2 Array{Any,2}:\n",
       " 0.27327    \"tabby, tabby cat\"        \n",
       " 0.253185   \"Egyptian cat\"            \n",
       " 0.248429   \"tiger cat\"               \n",
       " 0.060727   \"kit fox, Vulpes macrotis\"\n",
       " 0.0561707  \"red fox, Vulpes vulpes\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.173264 seconds (61.56 k allocations: 3.428 MiB, 81.30% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mClassifying\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "VGG.main(catfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg.jl (c) Deniz Yuret, İlker Kesen, 2016. Classifying images with the VGG model from http://www.robots.ox.ac.uk/~vgg/research/very_deep.\n",
      "opts=(:atype, \"KnetArray{Float32}\")(:top, 5)(:image, \"https://cvimg1.cardekho.com/p/237x156/in/mahindra/torro-25/mahindra-torro-25.jpg\")(:model, \"imagenet-vgg-verydeep-16\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mDownloading https://cvimg1.cardekho.com/p/237x156/in/mahindra/torro-25/mahindra-torro-25.jpg\n",
      "\u001b[39m  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 13411  100 13411    0     0   6702      0  0:00:02  0:00:02 --:--:--  6705\n",
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mClassifying\n",
      "\u001b[39m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5×2 Array{Any,2}:\n",
       " 0.899679    \"garbage truck, dustcart\"                                                   \n",
       " 0.0654105   \"moving van\"                                                                \n",
       " 0.0201083   \"crane\"                                                                     \n",
       " 0.00583589  \"trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi\"\n",
       " 0.00515393  \"snowplow, snowplough\"                                                      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.039080 seconds (1.85 k allocations: 90.297 KiB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VGG.main(\"https://cvimg1.cardekho.com/p/237x156/in/mahindra/torro-25/mahindra-torro-25.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
