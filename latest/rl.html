<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reinforcement Learning · Knet.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.5.0/styles/default.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Ubuntu+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="assets/documenter.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="../versions.js"></script></head><body><nav class="toc"><h1>Knet.jl</h1><form class="search" action="search.html"><select id="version-selector" onChange="window.location.href=this.value"><option value="#" selected="selected" disabled="disabled">Version</option></select><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="index.html">Home</a></li><li><span class="toctext">Manual</span><ul><li><a class="toctext" href="install.html">Setting up Knet</a></li><li><a class="toctext" href="tutorial.html">Introduction to Knet</a></li><li><a class="toctext" href="examples.html">Examples</a></li><li><a class="toctext" href="reference.html">Reference</a></li></ul></li><li><span class="toctext">Textbook</span><ul><li><a class="toctext" href="backprop.html">Backpropagation</a></li><li><a class="toctext" href="softmax.html">Softmax Classification</a></li><li><a class="toctext" href="mlp.html">Multilayer Perceptrons</a></li><li><a class="toctext" href="cnn.html">Convolutional Neural Networks</a></li><li><a class="toctext" href="rnn.html">Recurrent Neural Networks</a></li><li class="current"><a class="toctext" href="rl.html">Reinforcement Learning</a><ul class="internal"><li><a class="toctext" href="#References-1">References</a></li></ul></li><li><a class="toctext" href="opt.html">Optimization</a></li><li><a class="toctext" href="gen.html">Generalization</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Textbook</li><li><a href="rl.html">Reinforcement Learning</a></li></ul><a class="edit-page" href="https://github.com/denizyuret/Knet.jl/tree/e6835c90849c927d192c19ba0a0457ade7a20552/docs/src/rl.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/></header><h1><a class="nav-anchor" id="Reinforcement-Learning-1" href="#Reinforcement-Learning-1">Reinforcement Learning</a></h1><h2><a class="nav-anchor" id="References-1" href="#References-1">References</a></h2><ul><li><p>&lt;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html&gt;</p></li><li><p>&lt;https://www.youtube.com/watch?v=2pWv7GOvuf0&amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT&gt;</p></li><li><p>&lt;http://videolectures.net/rldm2015_silver_reinforcement_learning/?q=david%20silver&gt;</p></li><li><p>&lt;https://webdocs.cs.ualberta.ca/~sutton/book/the-book.html&gt;</p></li><li><p>&lt;https://sites.ualberta.ca/~szepesva/RLBook.html&gt;</p></li><li><p>&lt;http://banditalgs.com/print/&gt;</p></li><li><p>&lt;http://karpathy.github.io/2016/05/31/rl/&gt;</p></li><li><p>&lt;http://cs229.stanford.edu/notes/cs229-notes12.pdf&gt;</p></li><li><p>&lt;http://cs.stanford.edu/people/karpathy/reinforcejs/index.html&gt;</p></li><li><p>&lt;https://www.udacity.com/course/machine-learning-reinforcement-learning&gt;–ud820</p></li><li><p>&lt;http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html&gt;</p></li><li><p>&lt;http://people.csail.mit.edu/regina/my_papers/TG15.pdf&gt;</p></li><li><p>In &lt;http://karpathy.github.io/2015/05/21/rnn-effectiveness&gt;: For   more about REINFORCE and more generally Reinforcement Learning and   policy gradient methods (which REINFORCE is a special case of) David   Silver&#39;s class, or one of Pieter Abbeel&#39;s classes. This is very much   ongoing work but these hard attention models have been explored, for   example, in Inferring Algorithmic Patterns with Stack-Augmented   Recurrent Nets, Reinforcement Learning Neural Turing Machines, and   Show Attend and Tell.</p></li><li><p>In &lt;http://www.deeplearningbook.org/contents/ml.html&gt;: Please see   Sutton and Barto (1998) or Bertsekasand Tsitsiklis (1996) for   information about reinforcement learning, and Mnih et al.(2013) for   the deep learning approach to reinforcement learning.</p></li></ul><footer><hr/><a class="previous" href="rnn.html"><span class="direction">Previous</span><span class="title">Recurrent Neural Networks</span></a><a class="next" href="opt.html"><span class="direction">Next</span><span class="title">Optimization</span></a></footer></article></body></html>
